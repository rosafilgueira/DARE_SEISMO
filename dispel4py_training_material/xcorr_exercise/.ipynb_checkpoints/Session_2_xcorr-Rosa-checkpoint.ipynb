{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "In this exercise, we're going to build a small preprocessing workflow that prepares traces and then computes the cross correlation from the results.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from obspy.core import read\n",
    "sta1 = 'http://escience8.inf.ed.ac.uk:8080/laquila/SAC/A25A.TA..BHZ.2011.025.00.00.00.000-2011.026.00.00.39.000.rm.scale-AUTO.SAC'\n",
    "sta2 = 'http://escience8.inf.ed.ac.uk:8080/laquila/SAC/BMN.LB..BHZ.2011.025.00.00.00.023-2011.026.00.00.38.998.rm.scale-AUTO.SAC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two functions are similar to the ones in the previous session. The first one (stream_producer) reads a file that contains seismological traces and returns it as an obspy stream. The second one (readstats) extracts the station's start time, the station's name of the first trace and returns a stream with three values: station's starttime, station's name and the obspy stream. The reason for returning those values is that later we are going to group the data by station's start time for computing the cross correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py.base import SimpleFunctionPE, IterativePE, create_iterative_chain\n",
    "\n",
    "def stream_producer(data):\n",
    "    filename = data\n",
    "    st = read(filename)\n",
    "    return st\n",
    "\n",
    "def readstats(st):\n",
    "    station_date = st[0].stats['starttime'].date\n",
    "    station_day = station_date.strftime('%d-%m-%Y')\n",
    "    station = st[0].stats['station']\n",
    "    return [station_day, station, st]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to preprocess the trace data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'preprocess pipeline' which is a composite PE for processing several functions (decimate, detrend, demean and filter) in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decimate(st, sps):\n",
    "    st.decimate(int(st[0].stats.sampling_rate/sps))\n",
    "    return st\n",
    "\n",
    "def detrend(st):\n",
    "    st.detrend('simple')\n",
    "    return st\n",
    "\n",
    "def demean(st):\n",
    "    st.detrend('demean')\n",
    "    return st\n",
    "\n",
    "def filter(st, freqmin=0.01, freqmax=1., corners=4, zerophase=False):\n",
    "    st.filter('bandpass', freqmin=freqmin, freqmax=freqmax, corners=corners, zerophase=zerophase)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'preprocess pipeline' which is a composite PE for processing several functions (decimate, detren and deman) in a sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a pipeline of processing elements that run a list of functions, for example, this creates a chain with the functions decimate and detrend. Note that decimate has one parameter 'sps' with value 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_trace = create_iterative_chain([detrend ])\n",
    "\n",
    "preprocess_trace = create_iterative_chain([ (decimate, {'sps':4}), detrend, filter ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a composite PE which you can also visualise as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py.visualisation import display\n",
    "display(preprocess_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create another function for whitening obspy stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import arange, sqrt, abs, multiply, conjugate, real\n",
    "from obspy.signal.util import nextpow2\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "def spectralwhitening(st):\n",
    "    \"\"\"\n",
    "    Apply spectral whitening to data.\n",
    "    Data is divided by its smoothed (Default: None) amplitude spectrum.\n",
    "    \"\"\"\n",
    "    \n",
    "    for trace in arange(len(st)):\n",
    "        data = st[trace].data\n",
    "        \n",
    "        n = len(data)\n",
    "        nfft = nextpow2(n)\n",
    "        \n",
    "        spec = fft(data, nfft)\n",
    "        spec_ampl = sqrt(abs(multiply(spec, conjugate(spec))))\n",
    "        \n",
    "        spec /= spec_ampl  #Do we need to do some smoothing here?\n",
    "        ret = real(ifft(spec, nfft)[:n])\n",
    "        \n",
    "        st[trace].data = ret\n",
    "        \n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 1</h2>\n",
    "<p> \n",
    "Create your own function to preprocess the data. Later it could be added to the CompositePE. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def preprocess(data):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 2</h2>\n",
    "<p> \n",
    "Now it's time to create the graph for preprocessing the traces. \n",
    "\n",
    "An example of the filter parameter that can be used is :\n",
    "'freqmin':0.01, 'freqmax':1., 'corners':4, 'zerophase':False. \n",
    "\n",
    "Remenber that the worfklow first has to read the file that contains the traces, then preprocess them (composite PE), and finally extract the station's start time,  the station's name and stream. You can chose how many functions want to add to the create_iterative_chain for preprocess the traces.  \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py.workflow_graph import WorkflowGraph\n",
    "streamProducer = SimpleFunctionPE(stream_producer) \n",
    "streamProducer.name = \"streamProducer\"\n",
    "preprocess_trace = create_iterative_chain([ (decimate, {'sps': 4}), detrend, demean, spectralwhitening ])\n",
    "sta = SimpleFunctionPE(readstats)\n",
    "\n",
    "graph = WorkflowGraph()\n",
    "graph.connect(streamProducer, 'output', preprocess_trace,'input')\n",
    "graph.connect(preprocess_trace, 'output', sta,'input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Visualise the workflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 3</h2> \n",
    "<p>\n",
    "Finally execute the graph and preprocess the traces from two different stations. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dispel4py import simple_process\n",
    "input_data = { streamProducer : [ {'input' : sta1 }, {'input' : sta2 }] }\n",
    "graph.flatten()\n",
    "simple_process.process(graph, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Note:</h3> \n",
    "<p>\n",
    "For executing with another mappings, copy all the lines ( execept the last 3) into a script ( session2.py): <br/>\n",
    "<ul>\n",
    "<li > Multiprocessing mapping for shared memory machine (several cores in the same cpu):<br/>\n",
    "\n",
    "<tt> dispel4py multi session2 -n 4 <br/>\n",
    "    -d \"{ \\\"StreamProducer\\\" : [ { \\\"input\\\" : \\\"http://escience8.inf.ed.ac.uk:8080/laquila/SAC/A25A.TA..BHZ.2011.025.00.00.00.000-2011.026.00.00.39.000.rm.scale-AUTO.SAC\\\" }, { \\\"input\\\" : \\\"http://escience8.inf.ed.ac.uk:8080/laquila/SAC/BMN.LB..BHZ.2011.025.00.00.00.023-2011.026.00.00.38.998.rm.scale-AUTO.SAC\\\"} ] }\"</tt></li> \n",
    "\n",
    "\n",
    "    <li > MPI mapping for distributed memory machine (several cores in several cpus):<br/>\n",
    "\n",
    "<tt> mpiexec -n 4 dispel4py mpi session2  <br/>\n",
    "    -d \"{ \\\"StreamProducer\\\" : [ { \\\"input\\\" : \\\"http://escience8.inf.ed.ac.uk:8080/laquila/SAC/A25A.TA..BHZ.2011.025.00.00.00.000-2011.026.00.00.39.000.rm.scale-AUTO.SAC\\\" }, { \\\"input\\\" : \\\"http://escience8.inf.ed.ac.uk:8080/laquila/SAC/BMN.LB..BHZ.2011.025.00.00.00.023-2011.026.00.00.38.998.rm.scale-AUTO.SAC\\\"} ] }\"</tt></li> \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercise 4</h2> \n",
    "<p>\n",
    "Convert 'decimate' function into a IterativePE called DecimatePE. </p>\n",
    "<p>Modify the graph, for using the DecimatePE:</p>\n",
    "<ul>\n",
    "    <li> modify the compositePE (preprocess_trace) to remove decimate function from the creative_iterative_chain </li>\n",
    "    <li> create the decimatePE object </li>\n",
    "    <li>  connect streamProducer to decimantePE </li>\n",
    "    <li>  connect decimatePE to preprocess_trace </li>\n",
    "    <li>  ... </li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecimatePE(IterativePE):\n",
    "\n",
    "    def __init__(self, sps):\n",
    "        IterativePE.__init__(self)\n",
    "        self.sps = sps\n",
    "\n",
    "    def _process(self, data):\n",
    "        st = data\n",
    "        st.decimate(int(st[0].stats.sampling_rate/self.sps))\n",
    "        return st\n",
    "\n",
    "\n",
    "decimate = DecimatePE(4)\n",
    "preprocess_trace = create_iterative_chain([ ... ])\n",
    "streamProducer = ...\n",
    "\n",
    "graph = WorkflowGraph()\n",
    "graph.connect(streamProducer, 'output', decimate, 'input')\n",
    "graph.connect(decimate, 'output', preprocess_trace, 'input')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
